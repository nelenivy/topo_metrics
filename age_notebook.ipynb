{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spMVAySTSEZ1",
   "metadata": {
    "id": "spMVAySTSEZ1"
   },
   "source": [
    "# Colab setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "WyOYsMF2SEZ3",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyOYsMF2SEZ3",
    "outputId": "d4de792a-68f1-4f17-ddb0-120d89f7b39f"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# # if \"google.colab\" in str(get_ipython()):\n",
    "# ! {sys.executable} -m pip install pytorch-lifestream\n",
    "# ! {sys.executable} -m pip install catboost\n",
    "# ! {sys.executable} -m pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T6ZAv6VUd1pq",
   "metadata": {
    "id": "T6ZAv6VUd1pq"
   },
   "source": [
    "# Supervised task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ipR01Z_jd1pt",
   "metadata": {
    "id": "ipR01Z_jd1pt"
   },
   "source": [
    "## Prepare your data\n",
    "\n",
    "- Use `Pyspark` in local or cluster mode for big dataset and `Pandas` for small.\n",
    "- Split data into required parts (train, valid, test, ...).\n",
    "- Use `ptls.preprocessing` for simple data preparation.\n",
    "- Transform features to compatible format using `Pyspark` or `Pandas` functions.\n",
    "You can also use `ptls.data_load.preprocessing` for common data transformation patterns.\n",
    "- Split sequences to `ptls-data` format with `ptls.data_load.split_tools`. Save prepared data into `Parquet` format or\n",
    "keep it in memory (`Pickle` also works).\n",
    "- Use one of the available `ptls.data_load.datasets` to define input for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "Om-SP9LKd1pv",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Om-SP9LKd1pv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder, Head\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.preprocessing import PandasDataPreprocessor\n",
    "from ptls.frames.supervised import SeqToTargetDataset, SequenceToTarget\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from ptls.frames.inference_module import InferenceModule\n",
    "from ptls.frames.coles import CoLESModule\n",
    "from ptls.frames.coles.multimodal_dataset import MultiModalIterableDataset\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb16883-4df4-4c59-982c-2533cabb7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from datetime import timedelta\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import catboost\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ptls.nn import TrxEncoder\n",
    "from ptls.nn.seq_encoder.rnn_encoder import RnnEncoder\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.frames.coles import CoLESModule\n",
    "from ptls.frames.coles.split_strategy import SampleSlices\n",
    "from ptls.frames.coles.multimodal_dataset import MultiModalDataset\n",
    "from ptls.frames.coles.multimodal_dataset import MultiModalIterableDataset\n",
    "from ptls.frames.coles.multimodal_dataset import MultiModalSortTimeSeqEncoderContainer\n",
    "from ptls.frames.coles.multimodal_inference_dataset import MultiModalInferenceDataset\n",
    "from ptls.frames.coles.multimodal_inference_dataset import MultiModalInferenceIterableDataset\n",
    "from ptls.frames.inference_module import InferenceModuleMultimodal\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.data_load import IterableProcessingDataset\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.preprocessing import PandasDataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "H5e7oTeqd1py",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "H5e7oTeqd1py",
    "outputId": "3ad59ce8-fe24-4f3b-dc98-a35947910692"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24662</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34089</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47076</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>14303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>22301</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>25731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>16820</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>5265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       client_id  bins\n",
       "0          24662     2\n",
       "1           1046     0\n",
       "2          34089     2\n",
       "3          34848     1\n",
       "4          47076     3\n",
       "...          ...   ...\n",
       "29995      14303     1\n",
       "29996      22301     2\n",
       "29997      25731     0\n",
       "29998      16820     3\n",
       "29999       5265     0\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = pd.read_csv(\n",
    "    \"https://huggingface.co/datasets/dllllb/age-group-prediction/resolve/main/train_target.csv?download=true\"\n",
    ")\n",
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pvunZAm9d1pz",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "pvunZAm9d1pz",
    "outputId": "d8c825c8-9a2a-434a-8a1e-284d84373479"
   },
   "outputs": [],
   "source": [
    "# df_target_train, df_target_test = train_test_split(\n",
    "#     df_target, test_size=7000, stratify=df_target[\"bins\"], random_state=142)\n",
    "# df_target_train, df_target_valid = train_test_split(\n",
    "#     df_target_train, test_size=3000, stratify=df_target_train[\"bins\"], random_state=142)\n",
    "# print(\"Split {} records to train: {}, valid: {}, test: {}\".format(\n",
    "#     *[\n",
    "#       len(df)\n",
    "#       for df in [df_target, df_target_train, df_target_valid, df_target_test]\n",
    "#     ]\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Of3-MPEBd1pz",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Of3-MPEBd1pz",
    "outputId": "24771ae2-1236-40a0-da8c-5bdb9401ff56"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>small_group</th>\n",
       "      <th>amount_rur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33172</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>71.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33172</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>45.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33172</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>13.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33172</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>15.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33172</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>21.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26450572</th>\n",
       "      <td>43300</td>\n",
       "      <td>727</td>\n",
       "      <td>25</td>\n",
       "      <td>7.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26450573</th>\n",
       "      <td>43300</td>\n",
       "      <td>727</td>\n",
       "      <td>15</td>\n",
       "      <td>3.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26450574</th>\n",
       "      <td>43300</td>\n",
       "      <td>727</td>\n",
       "      <td>1</td>\n",
       "      <td>6.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26450575</th>\n",
       "      <td>43300</td>\n",
       "      <td>727</td>\n",
       "      <td>11</td>\n",
       "      <td>24.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26450576</th>\n",
       "      <td>43300</td>\n",
       "      <td>729</td>\n",
       "      <td>3</td>\n",
       "      <td>19.408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26450577 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          client_id  trans_date  small_group  amount_rur\n",
       "0             33172           6            4      71.463\n",
       "1             33172           6           35      45.017\n",
       "2             33172           8           11      13.887\n",
       "3             33172           9           11      15.983\n",
       "4             33172          10           11      21.341\n",
       "...             ...         ...          ...         ...\n",
       "26450572      43300         727           25       7.602\n",
       "26450573      43300         727           15       3.709\n",
       "26450574      43300         727            1       6.448\n",
       "26450575      43300         727           11      24.669\n",
       "26450576      43300         729            3      19.408\n",
       "\n",
       "[26450577 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trx = pd.read_csv(\n",
    "    \"https://huggingface.co/datasets/dllllb/age-group-prediction/resolve/main/transactions_train.csv.gz?download=true\",\n",
    "    compression=\"gzip\"\n",
    ")\n",
    "df_trx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3d8789e-25cc-44bc-8ab6-5a0e431a6a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec6d9d7-4fc4-4b20-8820-d23cb2cafb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26450577"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_trx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d885c788-eada-4416-b878-d8d1e25d9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceA = df_trx[[\"client_id\", \"trans_date\", \"small_group\"]]\n",
    "sourceB = df_trx[[\"client_id\", \"trans_date\", \"amount_rur\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f14522c-f37d-4747-91bd-f86d9d02cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceA_drop_indices = np.random.choice(sourceA.index, int(1500000), replace=False)\n",
    "sourceB_drop_indices = np.random.choice(sourceB.index, int(4500000), replace=False)\n",
    "\n",
    "sourceA = sourceA.drop(sourceA_drop_indices).reset_index(drop=True)\n",
    "sourceB = sourceB.drop(sourceB_drop_indices).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6024034f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24950577, 21950577)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sourceA), len(sourceB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bb6cd53-c7f2-4650-a11c-116f90cd3f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceA[\"trans_date\"] = sourceA[\"trans_date\"].apply(lambda x: x * 3600)\n",
    "sourceB[\"trans_date\"] = sourceB[\"trans_date\"].apply(lambda x: x * 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "372c69e4-ad51-436c-a66c-092917254c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceA_preprocessor = PandasDataPreprocessor(\n",
    "    col_id=\"client_id\",\n",
    "    col_event_time=\"trans_date\",\n",
    "    event_time_transformation=\"none\",\n",
    "    cols_category=[\"small_group\"],\n",
    "    return_records=False,\n",
    ")\n",
    "\n",
    "sourceB_preprocessor = PandasDataPreprocessor(\n",
    "    col_id=\"client_id\",\n",
    "    col_event_time=\"trans_date\",\n",
    "    event_time_transformation=\"none\",\n",
    "    cols_numerical=[\"amount_rur\"],\n",
    "    return_records=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88d0eef5-a35c-4be1-bc8b-820cf55e758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sourceA = sourceA_preprocessor.fit_transform(sourceA)\n",
    "processed_sourceB = sourceB_preprocessor.fit_transform(sourceB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "710408d0-befe-4fb0-8967-448f2291bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sourceA.columns = [\n",
    "    \"sourceA_\" + str(col) if str(col) != \"client_id\" else str(col)\n",
    "    for col in processed_sourceA.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1f3e6dd-25f8-4fb9-a93a-829332b8fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sourceB.columns = [\n",
    "    \"sourceB_\" + str(col) if str(col) != \"client_id\" else str(col)\n",
    "    for col in processed_sourceB.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4182f6b0-9f59-463d-aaec-3aa17ce79dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data = processed_sourceA.merge(processed_sourceB, how=\"outer\", on=\"client_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7856789e-a955-4caa-a8ea-56e9f6743d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>sourceA_trans_date</th>\n",
       "      <th>sourceA_event_time</th>\n",
       "      <th>sourceA_small_group</th>\n",
       "      <th>sourceB_trans_date</th>\n",
       "      <th>sourceB_event_time</th>\n",
       "      <th>sourceB_amount_rur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n",
       "      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n",
       "      <td>[tensor(1), tensor(3), tensor(1), tensor(1), t...</td>\n",
       "      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n",
       "      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n",
       "      <td>[tensor(10.2090, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>[tensor(0), tensor(18000), tensor(36000), tens...</td>\n",
       "      <td>[tensor(0), tensor(18000), tensor(36000), tens...</td>\n",
       "      <td>[tensor(4), tensor(3), tensor(1), tensor(3), t...</td>\n",
       "      <td>[tensor(18000), tensor(36000), tensor(39600), ...</td>\n",
       "      <td>[tensor(18000), tensor(36000), tensor(39600), ...</td>\n",
       "      <td>[tensor(13.7380, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n",
       "      <td>[tensor(3), tensor(52), tensor(1), tensor(2), ...</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n",
       "      <td>[tensor(18.3190, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n",
       "      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n",
       "      <td>[tensor(16), tensor(1), tensor(52), tensor(10)...</td>\n",
       "      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n",
       "      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n",
       "      <td>[tensor(9.3420, dtype=torch.float64), tensor(5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>[tensor(0), tensor(7200), tensor(21600), tenso...</td>\n",
       "      <td>[tensor(0), tensor(7200), tensor(21600), tenso...</td>\n",
       "      <td>[tensor(3), tensor(9), tensor(1), tensor(1), t...</td>\n",
       "      <td>[tensor(7200), tensor(21600), tensor(28800), t...</td>\n",
       "      <td>[tensor(7200), tensor(21600), tensor(28800), t...</td>\n",
       "      <td>[tensor(22.8980, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>49993</td>\n",
       "      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n",
       "      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n",
       "      <td>[tensor(10), tensor(49), tensor(37), tensor(21...</td>\n",
       "      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n",
       "      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n",
       "      <td>[tensor(78.8800, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>49995</td>\n",
       "      <td>[tensor(0), tensor(3600), tensor(3600), tensor...</td>\n",
       "      <td>[tensor(0), tensor(3600), tensor(3600), tensor...</td>\n",
       "      <td>[tensor(3), tensor(9), tensor(2), tensor(9), t...</td>\n",
       "      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n",
       "      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n",
       "      <td>[tensor(2.6520, dtype=torch.float64), tensor(9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>49996</td>\n",
       "      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n",
       "      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n",
       "      <td>[tensor(13), tensor(1), tensor(5), tensor(2), ...</td>\n",
       "      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n",
       "      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n",
       "      <td>[tensor(215.6500, dtype=torch.float64), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>49997</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n",
       "      <td>[tensor(32.1940, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>49998</td>\n",
       "      <td>[tensor(57600), tensor(57600), tensor(57600), ...</td>\n",
       "      <td>[tensor(57600), tensor(57600), tensor(57600), ...</td>\n",
       "      <td>[tensor(12), tensor(4), tensor(7), tensor(1), ...</td>\n",
       "      <td>[tensor(57600), tensor(57600), tensor(61200), ...</td>\n",
       "      <td>[tensor(57600), tensor(57600), tensor(61200), ...</td>\n",
       "      <td>[tensor(34.5890, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       client_id                                 sourceA_trans_date  \\\n",
       "0              4  [tensor(0), tensor(7200), tensor(10800), tenso...   \n",
       "1              6  [tensor(0), tensor(18000), tensor(36000), tens...   \n",
       "2              7  [tensor(3600), tensor(7200), tensor(43200), te...   \n",
       "3             10  [tensor(14400), tensor(14400), tensor(14400), ...   \n",
       "4             11  [tensor(0), tensor(7200), tensor(21600), tenso...   \n",
       "...          ...                                                ...   \n",
       "29995      49993  [tensor(3600), tensor(14400), tensor(14400), t...   \n",
       "29996      49995  [tensor(0), tensor(3600), tensor(3600), tensor...   \n",
       "29997      49996  [tensor(3600), tensor(3600), tensor(7200), ten...   \n",
       "29998      49997  [tensor(3600), tensor(7200), tensor(10800), te...   \n",
       "29999      49998  [tensor(57600), tensor(57600), tensor(57600), ...   \n",
       "\n",
       "                                      sourceA_event_time  \\\n",
       "0      [tensor(0), tensor(7200), tensor(10800), tenso...   \n",
       "1      [tensor(0), tensor(18000), tensor(36000), tens...   \n",
       "2      [tensor(3600), tensor(7200), tensor(43200), te...   \n",
       "3      [tensor(14400), tensor(14400), tensor(14400), ...   \n",
       "4      [tensor(0), tensor(7200), tensor(21600), tenso...   \n",
       "...                                                  ...   \n",
       "29995  [tensor(3600), tensor(14400), tensor(14400), t...   \n",
       "29996  [tensor(0), tensor(3600), tensor(3600), tensor...   \n",
       "29997  [tensor(3600), tensor(3600), tensor(7200), ten...   \n",
       "29998  [tensor(3600), tensor(7200), tensor(10800), te...   \n",
       "29999  [tensor(57600), tensor(57600), tensor(57600), ...   \n",
       "\n",
       "                                     sourceA_small_group  \\\n",
       "0      [tensor(1), tensor(3), tensor(1), tensor(1), t...   \n",
       "1      [tensor(4), tensor(3), tensor(1), tensor(3), t...   \n",
       "2      [tensor(3), tensor(52), tensor(1), tensor(2), ...   \n",
       "3      [tensor(16), tensor(1), tensor(52), tensor(10)...   \n",
       "4      [tensor(3), tensor(9), tensor(1), tensor(1), t...   \n",
       "...                                                  ...   \n",
       "29995  [tensor(10), tensor(49), tensor(37), tensor(21...   \n",
       "29996  [tensor(3), tensor(9), tensor(2), tensor(9), t...   \n",
       "29997  [tensor(13), tensor(1), tensor(5), tensor(2), ...   \n",
       "29998  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "29999  [tensor(12), tensor(4), tensor(7), tensor(1), ...   \n",
       "\n",
       "                                      sourceB_trans_date  \\\n",
       "0      [tensor(0), tensor(7200), tensor(10800), tenso...   \n",
       "1      [tensor(18000), tensor(36000), tensor(39600), ...   \n",
       "2      [tensor(3600), tensor(7200), tensor(43200), te...   \n",
       "3      [tensor(14400), tensor(14400), tensor(14400), ...   \n",
       "4      [tensor(7200), tensor(21600), tensor(28800), t...   \n",
       "...                                                  ...   \n",
       "29995  [tensor(3600), tensor(14400), tensor(14400), t...   \n",
       "29996  [tensor(3600), tensor(3600), tensor(7200), ten...   \n",
       "29997  [tensor(3600), tensor(3600), tensor(7200), ten...   \n",
       "29998  [tensor(3600), tensor(7200), tensor(10800), te...   \n",
       "29999  [tensor(57600), tensor(57600), tensor(61200), ...   \n",
       "\n",
       "                                      sourceB_event_time  \\\n",
       "0      [tensor(0), tensor(7200), tensor(10800), tenso...   \n",
       "1      [tensor(18000), tensor(36000), tensor(39600), ...   \n",
       "2      [tensor(3600), tensor(7200), tensor(43200), te...   \n",
       "3      [tensor(14400), tensor(14400), tensor(14400), ...   \n",
       "4      [tensor(7200), tensor(21600), tensor(28800), t...   \n",
       "...                                                  ...   \n",
       "29995  [tensor(3600), tensor(14400), tensor(14400), t...   \n",
       "29996  [tensor(3600), tensor(3600), tensor(7200), ten...   \n",
       "29997  [tensor(3600), tensor(3600), tensor(7200), ten...   \n",
       "29998  [tensor(3600), tensor(7200), tensor(10800), te...   \n",
       "29999  [tensor(57600), tensor(57600), tensor(61200), ...   \n",
       "\n",
       "                                      sourceB_amount_rur  \n",
       "0      [tensor(10.2090, dtype=torch.float64), tensor(...  \n",
       "1      [tensor(13.7380, dtype=torch.float64), tensor(...  \n",
       "2      [tensor(18.3190, dtype=torch.float64), tensor(...  \n",
       "3      [tensor(9.3420, dtype=torch.float64), tensor(5...  \n",
       "4      [tensor(22.8980, dtype=torch.float64), tensor(...  \n",
       "...                                                  ...  \n",
       "29995  [tensor(78.8800, dtype=torch.float64), tensor(...  \n",
       "29996  [tensor(2.6520, dtype=torch.float64), tensor(9...  \n",
       "29997  [tensor(215.6500, dtype=torch.float64), tensor...  \n",
       "29998  [tensor(32.1940, dtype=torch.float64), tensor(...  \n",
       "29999  [tensor(34.5890, dtype=torch.float64), tensor(...  \n",
       "\n",
       "[30000 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c977d07-5d04-4274-ae61-f6c596b55164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4147032/957751795.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  joined_data = joined_data.applymap(lambda x: torch.tensor([]) if pd.isna(x) else x)\n"
     ]
    }
   ],
   "source": [
    "joined_data = joined_data.applymap(lambda x: torch.tensor([]) if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f89fe5f-2e65-4d90-8b9a-222538f74bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(joined_data,\n",
    "                                     test_size=0.4,\n",
    "                                     random_state=42)\n",
    "train_df, valid_df = train_test_split(train_df,\n",
    "                                      test_size=0.1,\n",
    "                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "546903f8-6f88-4a25-9537-06afa93a954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae1f78f6-6ec6-489e-9ce8-b830a3e8657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = train_df.to_dict(\"records\")\n",
    "valid_dict = valid_df.to_dict(\"records\")\n",
    "test_dict = test_df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "901e08dd-db96-42d0-b850-e1ab5dbfa0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_features = {\n",
    "    \"sourceA\": {\n",
    "        \"categorical\": [\"small_group\"],\n",
    "        \"numeric\": [],\n",
    "    },\n",
    "    \"sourceB\": {\n",
    "        \"categorical\": [],\n",
    "        \"numeric\": [\"amount_rur\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebe6998b-3e9a-4fd5-9ba6-388f2e983416",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_test_data = MultiModalInferenceIterableDataset(\n",
    "    data = test_dict,\n",
    "    source_features = source_features,\n",
    "    col_id = \"client_id\",\n",
    "    col_time = \"trans_date\",\n",
    "    source_names = (\"sourceA\", \"sourceB\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9931523f-1deb-4f5a-b292-aa112b2a0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_test_loader = DataLoader(\n",
    "    dataset = inf_test_data,\n",
    "    collate_fn = partial(inf_test_data.collate_fn, col_id=\"client_id\"),\n",
    "    shuffle = False,\n",
    "    num_workers = 0,\n",
    "    batch_size = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea5913-06cd-44d8-b13e-946a731cb2eb",
   "metadata": {},
   "source": [
    "## MY CODe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fc679e5-45c7-4096-a0ef-fac34fa45605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'google-research' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/google-research/google-research.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63ad2596-da46-4de1-8b97-2d89a983b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"google-research/graph_embedding/metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cea746c-f5de-46f6-936b-3df3061b2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import (rankme,\n",
    "        coherence,\n",
    "        pseudo_condition_number,\n",
    "        alpha_req,\n",
    "        stable_rank,\n",
    "        ne_sum,\n",
    "        self_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26622396-c2bc-4975-a455-bf3265a44c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/simonzhang00/ripser-plusplus.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3acfe40f-5636-40b4-8916-56878eac40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ripserplusplus as rpp\n",
    "def ripser_metric(embeddings, u=None, s=None):\n",
    "    \n",
    "    diagrams = rpp.run(\"--format point-cloud\", embeddings)\n",
    "    persistence = {}\n",
    "\n",
    "    for k in range(len(diagrams)):\n",
    "        persistence_sum = sum([death - birth for birth, death in diagrams[k] if death > birth])\n",
    "        persistence[f\"ripser_sum_H{k}\"] = persistence_sum\n",
    "\n",
    "    return persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e00a1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "os.makedirs('logs/age', exist_ok=True)\n",
    "\n",
    "logger = logging.getLogger(\"my_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "file_handler = logging.FileHandler(\"logs/age/hidden_size_experiment.log\")\n",
    "formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# –£–¥–∞–ª–∏–º –¥—Ä—É–≥–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "logger.info(\"üîß –õ–æ–≥–≥–µ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω –≤—Ä—É—á–Ω—É—é\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ae2a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# random_embedding = np.random.rand(100, 8)\n",
    "\n",
    "# # üîπ –°–∞–Ω–∏—Ç–∏-—á–µ–∫\n",
    "# score, elapsed = ripser_metric(random_embedding)\n",
    "# print(f\"Ripser metric: {score:.4f}, computed in {elapsed:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b832a19-eb6d-4968-b7e7-84856ff80d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(train_dict, valid_dict, params, source_features):\n",
    "    splitter = SampleSlices(\n",
    "        split_count=params[\"split_count\"],\n",
    "        cnt_min=params[\"cnt_min\"],\n",
    "        cnt_max=params[\"cnt_max\"],\n",
    "    )\n",
    "\n",
    "    train_data = MultiModalIterableDataset(\n",
    "        data=train_dict,\n",
    "        splitter=splitter,\n",
    "        source_features=source_features,\n",
    "        col_id=\"client_id\",\n",
    "        col_time=\"trans_date\",\n",
    "        source_names=(\"sourceA\", \"sourceB\"),\n",
    "    )\n",
    "\n",
    "    valid_data = MultiModalIterableDataset(\n",
    "        data=valid_dict,\n",
    "        splitter=splitter,\n",
    "        source_features=source_features,\n",
    "        col_id=\"client_id\",\n",
    "        col_time=\"trans_date\",\n",
    "        source_names=(\"sourceA\", \"sourceB\"),\n",
    "    )\n",
    "\n",
    "    data_loader = PtlsDataModule(\n",
    "        train_data=train_data,\n",
    "        train_batch_size=params[\"batch_size\"],\n",
    "        train_num_workers=0,\n",
    "        valid_data=valid_data,\n",
    "    )\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c308cd5-1e80-4cf8-ba00-4858ea2aed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, pl_trainer, inf_test_loader, selected_metrics=None, n_samples=10, sample_fraction=1/20):\n",
    "    import gc\n",
    "    from sklearn.utils import resample\n",
    "    from time import time\n",
    "    logger.info(f\"{sample_fraction=}\")\n",
    "\n",
    "    model.eval()\n",
    "    inference_module = InferenceModuleMultimodal(\n",
    "        model=model,\n",
    "        pandas_output=True,\n",
    "        drop_seq_features=True,\n",
    "        model_out_name=\"emb\",\n",
    "        col_id=\"client_id\",\n",
    "    )\n",
    "    inference_module.model.is_reduce_sequence = True\n",
    "\n",
    "    # –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "    inf_test_embeddings = pd.concat(\n",
    "        pl_trainer.predict(inference_module, inf_test_loader),\n",
    "        axis=0,\n",
    "    )\n",
    "    embeddings_np = inf_test_embeddings.drop(columns=[\"client_id\"]).to_numpy(dtype=np.float32)\n",
    "    sample_size = max(1, int(sample_fraction * embeddings_np.shape[0]))\n",
    "\n",
    "    # –ú–µ—Ç—Ä–∏–∫–∏\n",
    "    available_metrics = {\n",
    "        \"rankme\": rankme,\n",
    "        \"coherence\": coherence,\n",
    "        \"pseudo_condition_number\": pseudo_condition_number,\n",
    "        \"alpha_req\": alpha_req,\n",
    "        \"stable_rank\": stable_rank,\n",
    "        \"ne_sum\": ne_sum,\n",
    "        \"self_clustering\": self_clustering,\n",
    "        \"ripser\": ripser_metric\n",
    "    }\n",
    "    if selected_metrics is None:\n",
    "        selected_metrics = list(available_metrics.keys())\n",
    "\n",
    "    metrics = {name: [] for name in selected_metrics}\n",
    "    times = {name: [] for name in selected_metrics}\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        sample = resample(embeddings_np, n_samples=sample_size, replace=False, random_state=42 + i)\n",
    "        u, s, _ = np.linalg.svd(sample, compute_uv=True, full_matrices=False)\n",
    "\n",
    "        for metric_name in selected_metrics:\n",
    "            if metric_name not in available_metrics:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                t0 = time()\n",
    "                result = available_metrics[metric_name](sample, u=u, s=s)\n",
    "                t = time() - t0\n",
    "\n",
    "                if isinstance(result, dict):\n",
    "                    for subname, val in result.items():\n",
    "                        if subname not in metrics:\n",
    "                            metrics[subname] = []\n",
    "                            times[subname] = []\n",
    "                        metrics[subname].append(val)\n",
    "                        times[subname].append(t)\n",
    "                else:\n",
    "                    if metric_name not in metrics:\n",
    "                        metrics[metric_name] = []\n",
    "                        times[metric_name] = []\n",
    "                    metrics[metric_name].append(result)\n",
    "                    times[metric_name].append(t)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Failed to compute {metric_name} on sample {i}: {e}\")\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    averaged_metrics = {k: np.mean(v) for k, v in metrics.items()}\n",
    "    std_metrics = {k: np.std(v) for k, v in metrics.items()}\n",
    "    \n",
    "    averaged_times = {k: np.mean(v) for k, v in times.items()}\n",
    "    std_times = {k: np.std(v) for k, v in times.items()}\n",
    "\n",
    "    print(\"\\nüìä –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –∏ –≤—Ä–µ–º—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è:\")\n",
    "    for metric_name in averaged_metrics:\n",
    "        metric_value = averaged_metrics[metric_name]\n",
    "        metric_time = averaged_times.get(metric_name, None)\n",
    "        print(f\"üß† {metric_name:30s} = {metric_value:.4f} | ‚è± {metric_time:.4f} —Å–µ–∫\")\n",
    "\n",
    "    return averaged_metrics, averaged_times, std_metrics, std_times, inf_test_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5afba88-ca89-4002-9e51-73f0c90458ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "\n",
    "\n",
    "def evaluate_model(model, pl_trainer, checkpoint=None, selected_metrics=None, sample_fraction=1/20):\n",
    "    model.eval()\n",
    "    metrics, times, std_metrics, std_times, inf_test_embeddings = compute_metrics(model, pl_trainer, inf_test_loader, selected_metrics, sample_fraction=sample_fraction)\n",
    "    targets_df = df_target.set_index(\"client_id\")\n",
    "    inf_test_df = inf_test_embeddings.merge(targets_df, how=\"inner\", on=\"client_id\").set_index(\"client_id\")\n",
    "    \n",
    "    X = inf_test_df.drop(columns=[\"bins\"])\n",
    "    y = inf_test_df[\"bins\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    classifier = catboost.CatBoostClassifier(\n",
    "        iterations=150,\n",
    "        random_seed=42,\n",
    "        verbose=0,\n",
    "    )\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy = classifier.score(X_test, y_test)\n",
    "\n",
    "    del classifier\n",
    "    \n",
    "    return metrics, times, std_metrics, std_times, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9423ffb-c641-49da-922a-f99f310a5420",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_params = {\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"split_count\": 3,\n",
    "    \"cnt_min\": 10,\n",
    "    \"cnt_max\": 50,\n",
    "    \"embedding_dim\": 16,  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "    \"category_embedding_dim\": 8,  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–π —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "    \"hidden_size\": 128,  # –†–∞–∑–º–µ—Ä —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
    "}\n",
    "\n",
    "# –°–ø–∏—Å–æ–∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –ø–µ—Ä–µ–±–æ—Ä–∞\n",
    "variable_params = {\n",
    "    # \"batch_size\": [32, 64, 128], \n",
    "    # \"learning_rate\": [0.0001, 0.001, 0.05],\n",
    "    # \"split_count\": [2, 3, 5],\n",
    "    # \"cnt_min\": [5, 10, 20],\n",
    "    # \"cnt_max\": [50, 80, 100],\n",
    "    # \"embedding_dim\": [8, 16, 32],\n",
    "    # \"category_embedding_dim\": [8, 16, 24],\n",
    "    \"hidden_size\": [64, 128, 256, 1024],\n",
    "}\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–±—Ä–∞—Ç—å\n",
    "all_hyperparameter_grids = []\n",
    "for variable_param_name, variable_param_values in variable_params.items():\n",
    "    for value in variable_param_values:\n",
    "        hyperparameter_grid = {**fixed_params, variable_param_name: value}\n",
    "        all_hyperparameter_grids.append((variable_param_name, hyperparameter_grid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32ff8195-6bc8-45f6-af73-0b9a4dd5a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = [\n",
    "    \"rankme\", \"coherence\", \"pseudo_condition_number\",\n",
    "    \"alpha_req\", \"stable_rank\", \"ne_sum\", \"self_clustering\", \"ripser\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ca1115d-c16e-4c72-a7c6-31d5f9f098dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_embedding_dims = {\n",
    "    \"small_group\": (150, fixed_params[\"category_embedding_dim\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad25eb4a-0a4e-4cd6-9d6b-3e38d3cc3faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "150285f7-e90d-4a43-bc9c-ebe88839196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = \"age/checkpoints\"\n",
    "os.makedirs(checkpoints_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7abe764b-1033-4e80-ac36-a01ea8af5eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SampleSlices(split_count=5, cnt_min=25, cnt_max=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40fce490-8628-4ddb-a0de-88a504127673",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogger(pl.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.early_stopping_epoch = None  # –ó–∞–ø–æ–º–Ω–∏–º, –Ω–∞ –∫–∞–∫–æ–π —ç–ø–æ—Ö–µ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞\n",
    "    \n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        train_loss = trainer.callback_metrics.get(\"train_loss\", None)\n",
    "        val_loss = trainer.callback_metrics.get(\"val_loss\", None)\n",
    "        \n",
    "        if train_loss is not None and val_loss is not None:\n",
    "            print(f\"Epoch {trainer.current_epoch}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # –ï—Å–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –ª–æ—Å—Å —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è - —Ñ–∏–∫—Å–∏—Ä—É–µ–º —ç–ø–æ—Ö—É –æ—Å—Ç–∞–Ω–æ–≤–∫–∏\n",
    "        if trainer.early_stopping_callback is not None and trainer.early_stopping_callback.wait_count == 0:\n",
    "            self.early_stopping_epoch = trainer.current_epoch\n",
    "\n",
    "\n",
    "custom_logger = CustomLogger()\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    mode=\"min\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1540f7bd-56fe-402f-81e9-f7761c272a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45b5a2f0-27bb-4f76-8eef-e9db0dc3b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm age_tr_params_tun_full.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f3a299f-0870-4455-b906-3c943c2fd927",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "output_csv = \"age_tr_hidden_size2.csv\"\n",
    "\n",
    "\n",
    "metric_keys = [\n",
    "    \"rankme\", \"coherence\", \"pseudo_condition_number\", \n",
    "    \"alpha_req\", \"stable_rank\", \"ne_sum\", \"self_clustering\", \"ripser_sum_H0\", \"ripser_sum_H1\"\n",
    "]\n",
    "\n",
    "columns = (\n",
    "    list(fixed_params.keys()) +\n",
    "    [\"checkpoint\", \"epoch_num\", \"accuracy\", \"early_stop_epoch\", \"hidden_size\", \"sample_fraction\"] +\n",
    "    [f\"metric_{k}\" for k in metric_keys] +\n",
    "    [f\"std_metric_{k}\" for k in metric_keys] +\n",
    "    [f\"time_{k}\" for k in metric_keys] +\n",
    "    [f\"std_time_{k}\" for k in metric_keys]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74305632-67ed-4eb6-aeeb-bb8f4fa57a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dpetrovitch/venv/lib/python3.12/site-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/dpetrovitch/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/dpetrovitch/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/dpetrovitch/experiments/age/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name               | Type                                  | Params | Mode \n",
      "-------------------------------------------------------------------------------------\n",
      "0 | _loss              | ContrastiveLoss                       | 0      | train\n",
      "1 | _seq_encoder       | MultiModalSortTimeSeqEncoderContainer | 33.7 K | train\n",
      "2 | _validation_metric | BatchRecallTopK                       | 0      | train\n",
      "3 | _head              | Head                                  | 0      | train\n",
      "-------------------------------------------------------------------------------------\n",
      "33.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.7 K    Total params\n",
      "0.135     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcb3cb68e9646baad4175e4158ebbbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                       | 0/?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dpetrovitch/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/dpetrovitch/venv/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
      "/home/dpetrovitch/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a608c6b4618413ead83aac84d713217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                              | 0/?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eabb4ab811f4b42aaaf947dfb288729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric loss improved. New best score: 6.007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d9bcce67ba473ea19bd5f347c9c554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric loss improved by 0.741 >= min_delta = 0.0. New best score: 5.267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40b0b3e57c044458952658111ef0a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02646a1d4a22405481457a37854986e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80750ca59e7149ff8246e4106f2153c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric loss improved by 0.019 >= min_delta = 0.0. New best score: 5.248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b91c5546f074d9f82e5d738d4b99b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea659e1576640d6b420d033fded4ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029cb18c219442aeb2da9838a4059154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric loss improved by 0.503 >= min_delta = 0.0. New best score: 4.744\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334e815dcb5345519f3cd7b2fec8f9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4aa6a7f224d4e6ebada0eef38984416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532f6b2029de4d89bb2d44ee9cc48be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5399e8e50f394446ae97afe0a4c55c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import time\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from functools import partial\n",
    "\n",
    "cur_time = time()\n",
    "\n",
    "for param in all_hyperparameter_grids:\n",
    "    \n",
    "    logger.info(f'All params are frozen except {param[0]}')\n",
    "    params = param[1]\n",
    "    logger.info(f\"Testing parameters: {params}\")\n",
    "\n",
    "    train_loader = create_datasets(train_dict, valid_dict, params, source_features)\n",
    "\n",
    "    sourceA_encoder_params = dict(\n",
    "        embeddings_noise=0.003,\n",
    "        linear_projection_size=64,\n",
    "        embeddings={\n",
    "            \"small_group\": {\"in\": len(np.unique(sourceA['small_group'])), \"out\": 32}\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    sourceB_encoder_params = dict(\n",
    "        embeddings_noise=0.003,\n",
    "        linear_projection_size=64,\n",
    "        numeric_values={\"amount_rur\": \"identity\"},\n",
    "    )\n",
    "    \n",
    "    sourceA_encoder = TrxEncoder(**sourceA_encoder_params)\n",
    "    sourceB_encoder = TrxEncoder(**sourceB_encoder_params)\n",
    "    \n",
    "    seq_encoder = MultiModalSortTimeSeqEncoderContainer(\n",
    "        trx_encoders={\n",
    "            \"sourceA\": sourceA_encoder,\n",
    "            \"sourceB\": sourceB_encoder,\n",
    "        },\n",
    "        input_size=64,\n",
    "        hidden_size=params[\"hidden_size\"],  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ hidden_size\n",
    "        seq_encoder_cls=RnnEncoder,\n",
    "        type=\"gru\",\n",
    "    )\n",
    "\n",
    "    model = CoLESModule(\n",
    "        seq_encoder=seq_encoder,\n",
    "        optimizer_partial=partial(torch.optim.Adam, lr=params[\"learning_rate\"]),\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=10, gamma=0.5),\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor=\"loss\",\n",
    "        patience=5,\n",
    "        mode=\"min\",\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=checkpoints_path,\n",
    "        filename=f\"model_{params['batch_size']}_{params['learning_rate']}_{params['split_count']}_{params['cnt_min']}_{params['cnt_max']}_{params['hidden_size']}{{epoch:02d}}\",\n",
    "        save_top_k=-1,\n",
    "        every_n_epochs=1,\n",
    "    )\n",
    "\n",
    "    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "    pl_trainer = pl.Trainer(\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback, custom_logger],\n",
    "        default_root_dir=checkpoints_path,\n",
    "        check_val_every_n_epoch=1,\n",
    "        max_epochs= num_epochs,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        precision=16\n",
    "    )\n",
    "    model.train()\n",
    "    pl_trainer.fit(model, train_loader)\n",
    "\n",
    "    early_stop_epoch = getattr(custom_logger, \"early_stopping_epoch\", None) or num_epochs\n",
    "\n",
    "    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤\n",
    "    checkpoint_files = glob.glob(f\"{checkpoints_path}/model_{params['batch_size']}_{params['learning_rate']}_{params['split_count']}_{params['cnt_min']}_{params['cnt_max']}_{params['hidden_size']}*.ckpt\")\n",
    "    checkpoint_files.sort()\n",
    "    logger.info(f\"Elapsed time: {time() - cur_time:.2f} seconds\")\n",
    "\n",
    "    logger.info(f'Early stop is {early_stop_epoch}')\n",
    "\n",
    "    for i, checkpoint in enumerate(checkpoint_files):\n",
    "        logger.info(f\"Processing checkpoint number {i}\")\n",
    "        model = CoLESModule.load_from_checkpoint(checkpoint, seq_encoder=seq_encoder)\n",
    "    \n",
    "        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫, –≤—Ä–µ–º–µ–Ω–∏, –¥–∏—Å–ø–µ—Ä—Å–∏–π –∏ accuracy\n",
    "        metrics, times, std_metrics, std_times, accuracy = evaluate_model(model, pl_trainer, checkpoint, sample_fraction=sample_fraction)\n",
    "    \n",
    "        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –ø–ª–æ—Å–∫–∏–µ —Å–ª–æ–≤–∞—Ä–∏\n",
    "        metrics_flattened = {f\"metric_{k}\": round(v, 4) for k, v in metrics.items()}\n",
    "        std_metrics_flattened = {f\"std_metric_{k}\": round(v, 4) for k, v in std_metrics.items()}\n",
    "        times_flattened = {f\"time_{k}\": round(v, 4) for k, v in times.items()}\n",
    "        std_times_flattened = {f\"std_time_{k}\": round(v, 4) for k, v in std_times.items()}\n",
    "    \n",
    "        # –°–±–æ—Ä –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "        new_result = {\n",
    "            **params,\n",
    "            \"checkpoint\": checkpoint,\n",
    "            \"epoch_num\": int(i),\n",
    "            \"accuracy\": accuracy,\n",
    "            \"early_stop_epoch\": int(early_stop_epoch),\n",
    "            \"sample_fraction\": sample_fraction,\n",
    "            **metrics_flattened,\n",
    "            **std_metrics_flattened,\n",
    "            **times_flattened,\n",
    "            **std_times_flattened,\n",
    "        }\n",
    "    \n",
    "        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV\n",
    "        results = pd.DataFrame([new_result], columns=columns)\n",
    "\n",
    "        if not os.path.exists(output_csv):  \n",
    "            pd.DataFrame(columns=columns).to_csv(output_csv, mode=\"w\", index=False, header=True)\n",
    "            logger.info('csv file was created!')\n",
    "        \n",
    "        results.to_csv(output_csv, mode=\"a\", header=False, index=False)\n",
    "        \n",
    "\n",
    "        del metrics, accuracy, new_result\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    logger.info(f\"Removing checkpoints for parameters: {params}\")\n",
    "    for checkpoint in checkpoint_files:\n",
    "        os.remove(checkpoint)\n",
    "\n",
    "    del model\n",
    "    del train_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "logger.info(\"Optimization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2679bf0-29dc-41d4-808a-6ec4dfcb1cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
