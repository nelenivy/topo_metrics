{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spMVAySTSEZ1",
   "metadata": {
    "id": "spMVAySTSEZ1"
   },
   "source": [
    "# Colab setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "WyOYsMF2SEZ3",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyOYsMF2SEZ3",
    "outputId": "d4de792a-68f1-4f17-ddb0-120d89f7b39f"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# # if \"google.colab\" in str(get_ipython()):\n",
    "# ! {sys.executable} -m pip install pytorch-lifestream\n",
    "# ! {sys.executable} -m pip install catboost\n",
    "# ! {sys.executable} -m pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T6ZAv6VUd1pq",
   "metadata": {
    "id": "T6ZAv6VUd1pq"
   },
   "source": [
    "# Supervised task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ipR01Z_jd1pt",
   "metadata": {
    "id": "ipR01Z_jd1pt"
   },
   "source": [
    "## Prepare your data\n",
    "\n",
    "- Use `Pyspark` in local or cluster mode for big dataset and `Pandas` for small.\n",
    "- Split data into required parts (train, valid, test, ...).\n",
    "- Use `ptls.preprocessing` for simple data preparation.\n",
    "- Transform features to compatible format using `Pyspark` or `Pandas` functions.\n",
    "You can also use `ptls.data_load.preprocessing` for common data transformation patterns.\n",
    "- Split sequences to `ptls-data` format with `ptls.data_load.split_tools`. Save prepared data into `Parquet` format or\n",
    "keep it in memory (`Pickle` also works).\n",
    "- Use one of the available `ptls.data_load.datasets` to define input for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "Om-SP9LKd1pv",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Om-SP9LKd1pv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder, Head\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.preprocessing import PandasDataPreprocessor\n",
    "from ptls.frames.supervised import SeqToTargetDataset, SequenceToTarget\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from ptls.frames.inference_module import InferenceModule\n",
    "from ptls.frames.coles import CoLESModule\n",
    "from ptls.frames.coles.multimodal_dataset import MultiModalIterableDataset\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb16883-4df4-4c59-982c-2533cabb7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from datetime import timedelta\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import catboost\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ptls.nn import TrxEncoder\n",
    "from ptls.nn.seq_encoder.rnn_encoder import RnnEncoder\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.frames.coles import CoLESModule\n",
    "from ptls.frames.coles.split_strategy import SampleSlices\n",
    "from ptls.frames.coles.multimodal_dataset import MultiModalDataset\n",
    "from ptls.frames.coles.multimodal_dataset import MultiModalIterableDataset\n",
    "from ptls.frames.coles.multimodal_dataset import MultiModalSortTimeSeqEncoderContainer\n",
    "from ptls.frames.coles.multimodal_inference_dataset import MultiModalInferenceDataset\n",
    "from ptls.frames.coles.multimodal_inference_dataset import MultiModalInferenceIterableDataset\n",
    "from ptls.frames.inference_module import InferenceModuleMultimodal\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.data_load import IterableProcessingDataset\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.preprocessing import PandasDataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "H5e7oTeqd1py",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "H5e7oTeqd1py",
    "outputId": "3ad59ce8-fe24-4f3b-dc98-a35947910692"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24662</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34089</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47076</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>14303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>22301</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>25731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>16820</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>5265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       client_id  bins\n",
       "0          24662     2\n",
       "1           1046     0\n",
       "2          34089     2\n",
       "3          34848     1\n",
       "4          47076     3\n",
       "...          ...   ...\n",
       "29995      14303     1\n",
       "29996      22301     2\n",
       "29997      25731     0\n",
       "29998      16820     3\n",
       "29999       5265     0\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = pd.read_csv(\n",
    "    \"https://huggingface.co/datasets/dllllb/age-group-prediction/resolve/main/train_target.csv?download=true\"\n",
    ")\n",
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pvunZAm9d1pz",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "pvunZAm9d1pz",
    "outputId": "d8c825c8-9a2a-434a-8a1e-284d84373479"
   },
   "outputs": [],
   "source": [
    "# df_target_train, df_target_test = train_test_split(\n",
    "#     df_target, test_size=7000, stratify=df_target[\"bins\"], random_state=142)\n",
    "# df_target_train, df_target_valid = train_test_split(\n",
    "#     df_target_train, test_size=3000, stratify=df_target_train[\"bins\"], random_state=142)\n",
    "# print(\"Split {} records to train: {}, valid: {}, test: {}\".format(\n",
    "#     *[\n",
    "#       len(df)\n",
    "#       for df in [df_target, df_target_train, df_target_valid, df_target_test]\n",
    "#     ]\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Of3-MPEBd1pz",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Of3-MPEBd1pz",
    "outputId": "24771ae2-1236-40a0-da8c-5bdb9401ff56"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>small_group</th>\n",
       "      <th>amount_rur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33172</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>71.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33172</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>45.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33172</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>13.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33172</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>15.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33172</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>21.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26450572</th>\n",
       "      <td>43300</td>\n",
       "      <td>727</td>\n",
       "      <td>25</td>\n",
       "      <td>7.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26450573</th>\n",
       "      <td>43300</td>\n",
       "      <td>727</td>\n",
       "      <td>15</td>\n",
       "      <td>3.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26450574</th>\n",
       "      <td>43300</td>\n",
       "      <td>727</td>\n",
       "      <td>1</td>\n",
       "      <td>6.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26450575</th>\n",
       "      <td>43300</td>\n",
       "      <td>727</td>\n",
       "      <td>11</td>\n",
       "      <td>24.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26450576</th>\n",
       "      <td>43300</td>\n",
       "      <td>729</td>\n",
       "      <td>3</td>\n",
       "      <td>19.408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26450577 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          client_id  trans_date  small_group  amount_rur\n",
       "0             33172           6            4      71.463\n",
       "1             33172           6           35      45.017\n",
       "2             33172           8           11      13.887\n",
       "3             33172           9           11      15.983\n",
       "4             33172          10           11      21.341\n",
       "...             ...         ...          ...         ...\n",
       "26450572      43300         727           25       7.602\n",
       "26450573      43300         727           15       3.709\n",
       "26450574      43300         727            1       6.448\n",
       "26450575      43300         727           11      24.669\n",
       "26450576      43300         729            3      19.408\n",
       "\n",
       "[26450577 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trx = pd.read_csv(\n",
    "    \"https://huggingface.co/datasets/dllllb/age-group-prediction/resolve/main/transactions_train.csv.gz?download=true\",\n",
    "    compression=\"gzip\"\n",
    ")\n",
    "df_trx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3d8789e-25cc-44bc-8ab6-5a0e431a6a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec6d9d7-4fc4-4b20-8820-d23cb2cafb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26450577"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_trx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d885c788-eada-4416-b878-d8d1e25d9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceA = df_trx[[\"client_id\", \"trans_date\", \"small_group\"]]\n",
    "sourceB = df_trx[[\"client_id\", \"trans_date\", \"amount_rur\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f14522c-f37d-4747-91bd-f86d9d02cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceA_drop_indices = np.random.choice(sourceA.index, int(1500000), replace=False)\n",
    "sourceB_drop_indices = np.random.choice(sourceB.index, int(4500000), replace=False)\n",
    "\n",
    "sourceA = sourceA.drop(sourceA_drop_indices).reset_index(drop=True)\n",
    "sourceB = sourceB.drop(sourceB_drop_indices).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6024034f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24950577, 21950577)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sourceA), len(sourceB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bb6cd53-c7f2-4650-a11c-116f90cd3f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceA[\"trans_date\"] = sourceA[\"trans_date\"].apply(lambda x: x * 3600)\n",
    "sourceB[\"trans_date\"] = sourceB[\"trans_date\"].apply(lambda x: x * 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "372c69e4-ad51-436c-a66c-092917254c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceA_preprocessor = PandasDataPreprocessor(\n",
    "    col_id=\"client_id\",\n",
    "    col_event_time=\"trans_date\",\n",
    "    event_time_transformation=\"none\",\n",
    "    cols_category=[\"small_group\"],\n",
    "    return_records=False,\n",
    ")\n",
    "\n",
    "sourceB_preprocessor = PandasDataPreprocessor(\n",
    "    col_id=\"client_id\",\n",
    "    col_event_time=\"trans_date\",\n",
    "    event_time_transformation=\"none\",\n",
    "    cols_numerical=[\"amount_rur\"],\n",
    "    return_records=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88d0eef5-a35c-4be1-bc8b-820cf55e758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sourceA = sourceA_preprocessor.fit_transform(sourceA)\n",
    "processed_sourceB = sourceB_preprocessor.fit_transform(sourceB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "710408d0-befe-4fb0-8967-448f2291bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sourceA.columns = [\n",
    "    \"sourceA_\" + str(col) if str(col) != \"client_id\" else str(col)\n",
    "    for col in processed_sourceA.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1f3e6dd-25f8-4fb9-a93a-829332b8fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sourceB.columns = [\n",
    "    \"sourceB_\" + str(col) if str(col) != \"client_id\" else str(col)\n",
    "    for col in processed_sourceB.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4182f6b0-9f59-463d-aaec-3aa17ce79dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data = processed_sourceA.merge(processed_sourceB, how=\"outer\", on=\"client_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7856789e-a955-4caa-a8ea-56e9f6743d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>sourceA_trans_date</th>\n",
       "      <th>sourceA_event_time</th>\n",
       "      <th>sourceA_small_group</th>\n",
       "      <th>sourceB_trans_date</th>\n",
       "      <th>sourceB_event_time</th>\n",
       "      <th>sourceB_amount_rur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n",
       "      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n",
       "      <td>[tensor(1), tensor(3), tensor(1), tensor(1), t...</td>\n",
       "      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n",
       "      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n",
       "      <td>[tensor(10.2090, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>[tensor(0), tensor(18000), tensor(36000), tens...</td>\n",
       "      <td>[tensor(0), tensor(18000), tensor(36000), tens...</td>\n",
       "      <td>[tensor(4), tensor(3), tensor(1), tensor(3), t...</td>\n",
       "      <td>[tensor(18000), tensor(36000), tensor(39600), ...</td>\n",
       "      <td>[tensor(18000), tensor(36000), tensor(39600), ...</td>\n",
       "      <td>[tensor(13.7380, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n",
       "      <td>[tensor(3), tensor(52), tensor(1), tensor(2), ...</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n",
       "      <td>[tensor(18.3190, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n",
       "      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n",
       "      <td>[tensor(16), tensor(1), tensor(52), tensor(10)...</td>\n",
       "      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n",
       "      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n",
       "      <td>[tensor(9.3420, dtype=torch.float64), tensor(5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>[tensor(0), tensor(7200), tensor(21600), tenso...</td>\n",
       "      <td>[tensor(0), tensor(7200), tensor(21600), tenso...</td>\n",
       "      <td>[tensor(3), tensor(9), tensor(1), tensor(1), t...</td>\n",
       "      <td>[tensor(7200), tensor(21600), tensor(28800), t...</td>\n",
       "      <td>[tensor(7200), tensor(21600), tensor(28800), t...</td>\n",
       "      <td>[tensor(22.8980, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>49993</td>\n",
       "      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n",
       "      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n",
       "      <td>[tensor(10), tensor(49), tensor(37), tensor(21...</td>\n",
       "      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n",
       "      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n",
       "      <td>[tensor(78.8800, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>49995</td>\n",
       "      <td>[tensor(0), tensor(3600), tensor(3600), tensor...</td>\n",
       "      <td>[tensor(0), tensor(3600), tensor(3600), tensor...</td>\n",
       "      <td>[tensor(3), tensor(9), tensor(2), tensor(9), t...</td>\n",
       "      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n",
       "      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n",
       "      <td>[tensor(2.6520, dtype=torch.float64), tensor(9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>49996</td>\n",
       "      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n",
       "      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n",
       "      <td>[tensor(13), tensor(1), tensor(5), tensor(2), ...</td>\n",
       "      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n",
       "      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n",
       "      <td>[tensor(215.6500, dtype=torch.float64), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>49997</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n",
       "      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n",
       "      <td>[tensor(32.1940, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>49998</td>\n",
       "      <td>[tensor(57600), tensor(57600), tensor(57600), ...</td>\n",
       "      <td>[tensor(57600), tensor(57600), tensor(57600), ...</td>\n",
       "      <td>[tensor(12), tensor(4), tensor(7), tensor(1), ...</td>\n",
       "      <td>[tensor(57600), tensor(57600), tensor(61200), ...</td>\n",
       "      <td>[tensor(57600), tensor(57600), tensor(61200), ...</td>\n",
       "      <td>[tensor(34.5890, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       client_id                                 sourceA_trans_date  \\\n",
       "0              4  [tensor(0), tensor(7200), tensor(10800), tenso...   \n",
       "1              6  [tensor(0), tensor(18000), tensor(36000), tens...   \n",
       "2              7  [tensor(3600), tensor(7200), tensor(43200), te...   \n",
       "3             10  [tensor(14400), tensor(14400), tensor(14400), ...   \n",
       "4             11  [tensor(0), tensor(7200), tensor(21600), tenso...   \n",
       "...          ...                                                ...   \n",
       "29995      49993  [tensor(3600), tensor(14400), tensor(14400), t...   \n",
       "29996      49995  [tensor(0), tensor(3600), tensor(3600), tensor...   \n",
       "29997      49996  [tensor(3600), tensor(3600), tensor(7200), ten...   \n",
       "29998      49997  [tensor(3600), tensor(7200), tensor(10800), te...   \n",
       "29999      49998  [tensor(57600), tensor(57600), tensor(57600), ...   \n",
       "\n",
       "                                      sourceA_event_time  \\\n",
       "0      [tensor(0), tensor(7200), tensor(10800), tenso...   \n",
       "1      [tensor(0), tensor(18000), tensor(36000), tens...   \n",
       "2      [tensor(3600), tensor(7200), tensor(43200), te...   \n",
       "3      [tensor(14400), tensor(14400), tensor(14400), ...   \n",
       "4      [tensor(0), tensor(7200), tensor(21600), tenso...   \n",
       "...                                                  ...   \n",
       "29995  [tensor(3600), tensor(14400), tensor(14400), t...   \n",
       "29996  [tensor(0), tensor(3600), tensor(3600), tensor...   \n",
       "29997  [tensor(3600), tensor(3600), tensor(7200), ten...   \n",
       "29998  [tensor(3600), tensor(7200), tensor(10800), te...   \n",
       "29999  [tensor(57600), tensor(57600), tensor(57600), ...   \n",
       "\n",
       "                                     sourceA_small_group  \\\n",
       "0      [tensor(1), tensor(3), tensor(1), tensor(1), t...   \n",
       "1      [tensor(4), tensor(3), tensor(1), tensor(3), t...   \n",
       "2      [tensor(3), tensor(52), tensor(1), tensor(2), ...   \n",
       "3      [tensor(16), tensor(1), tensor(52), tensor(10)...   \n",
       "4      [tensor(3), tensor(9), tensor(1), tensor(1), t...   \n",
       "...                                                  ...   \n",
       "29995  [tensor(10), tensor(49), tensor(37), tensor(21...   \n",
       "29996  [tensor(3), tensor(9), tensor(2), tensor(9), t...   \n",
       "29997  [tensor(13), tensor(1), tensor(5), tensor(2), ...   \n",
       "29998  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "29999  [tensor(12), tensor(4), tensor(7), tensor(1), ...   \n",
       "\n",
       "                                      sourceB_trans_date  \\\n",
       "0      [tensor(0), tensor(7200), tensor(10800), tenso...   \n",
       "1      [tensor(18000), tensor(36000), tensor(39600), ...   \n",
       "2      [tensor(3600), tensor(7200), tensor(43200), te...   \n",
       "3      [tensor(14400), tensor(14400), tensor(14400), ...   \n",
       "4      [tensor(7200), tensor(21600), tensor(28800), t...   \n",
       "...                                                  ...   \n",
       "29995  [tensor(3600), tensor(14400), tensor(14400), t...   \n",
       "29996  [tensor(3600), tensor(3600), tensor(7200), ten...   \n",
       "29997  [tensor(3600), tensor(3600), tensor(7200), ten...   \n",
       "29998  [tensor(3600), tensor(7200), tensor(10800), te...   \n",
       "29999  [tensor(57600), tensor(57600), tensor(61200), ...   \n",
       "\n",
       "                                      sourceB_event_time  \\\n",
       "0      [tensor(0), tensor(7200), tensor(10800), tenso...   \n",
       "1      [tensor(18000), tensor(36000), tensor(39600), ...   \n",
       "2      [tensor(3600), tensor(7200), tensor(43200), te...   \n",
       "3      [tensor(14400), tensor(14400), tensor(14400), ...   \n",
       "4      [tensor(7200), tensor(21600), tensor(28800), t...   \n",
       "...                                                  ...   \n",
       "29995  [tensor(3600), tensor(14400), tensor(14400), t...   \n",
       "29996  [tensor(3600), tensor(3600), tensor(7200), ten...   \n",
       "29997  [tensor(3600), tensor(3600), tensor(7200), ten...   \n",
       "29998  [tensor(3600), tensor(7200), tensor(10800), te...   \n",
       "29999  [tensor(57600), tensor(57600), tensor(61200), ...   \n",
       "\n",
       "                                      sourceB_amount_rur  \n",
       "0      [tensor(10.2090, dtype=torch.float64), tensor(...  \n",
       "1      [tensor(13.7380, dtype=torch.float64), tensor(...  \n",
       "2      [tensor(18.3190, dtype=torch.float64), tensor(...  \n",
       "3      [tensor(9.3420, dtype=torch.float64), tensor(5...  \n",
       "4      [tensor(22.8980, dtype=torch.float64), tensor(...  \n",
       "...                                                  ...  \n",
       "29995  [tensor(78.8800, dtype=torch.float64), tensor(...  \n",
       "29996  [tensor(2.6520, dtype=torch.float64), tensor(9...  \n",
       "29997  [tensor(215.6500, dtype=torch.float64), tensor...  \n",
       "29998  [tensor(32.1940, dtype=torch.float64), tensor(...  \n",
       "29999  [tensor(34.5890, dtype=torch.float64), tensor(...  \n",
       "\n",
       "[30000 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c977d07-5d04-4274-ae61-f6c596b55164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4147032/957751795.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  joined_data = joined_data.applymap(lambda x: torch.tensor([]) if pd.isna(x) else x)\n"
     ]
    }
   ],
   "source": [
    "joined_data = joined_data.applymap(lambda x: torch.tensor([]) if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f89fe5f-2e65-4d90-8b9a-222538f74bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(joined_data,\n",
    "                                     test_size=0.4,\n",
    "                                     random_state=42)\n",
    "train_df, valid_df = train_test_split(train_df,\n",
    "                                      test_size=0.1,\n",
    "                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "546903f8-6f88-4a25-9537-06afa93a954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae1f78f6-6ec6-489e-9ce8-b830a3e8657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = train_df.to_dict(\"records\")\n",
    "valid_dict = valid_df.to_dict(\"records\")\n",
    "test_dict = test_df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "901e08dd-db96-42d0-b850-e1ab5dbfa0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_features = {\n",
    "    \"sourceA\": {\n",
    "        \"categorical\": [\"small_group\"],\n",
    "        \"numeric\": [],\n",
    "    },\n",
    "    \"sourceB\": {\n",
    "        \"categorical\": [],\n",
    "        \"numeric\": [\"amount_rur\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebe6998b-3e9a-4fd5-9ba6-388f2e983416",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_test_data = MultiModalInferenceIterableDataset(\n",
    "    data = test_dict,\n",
    "    source_features = source_features,\n",
    "    col_id = \"client_id\",\n",
    "    col_time = \"trans_date\",\n",
    "    source_names = (\"sourceA\", \"sourceB\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9931523f-1deb-4f5a-b292-aa112b2a0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_test_loader = DataLoader(\n",
    "    dataset = inf_test_data,\n",
    "    collate_fn = partial(inf_test_data.collate_fn, col_id=\"client_id\"),\n",
    "    shuffle = False,\n",
    "    num_workers = 0,\n",
    "    batch_size = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea5913-06cd-44d8-b13e-946a731cb2eb",
   "metadata": {},
   "source": [
    "## MY CODe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fc679e5-45c7-4096-a0ef-fac34fa45605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'google-research' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/google-research/google-research.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63ad2596-da46-4de1-8b97-2d89a983b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"google-research/graph_embedding/metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cea746c-f5de-46f6-936b-3df3061b2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import (rankme,\n",
    "        coherence,\n",
    "        pseudo_condition_number,\n",
    "        alpha_req,\n",
    "        stable_rank,\n",
    "        ne_sum,\n",
    "        self_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26622396-c2bc-4975-a455-bf3265a44c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/simonzhang00/ripser-plusplus.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3acfe40f-5636-40b4-8916-56878eac40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ripserplusplus as rpp\n",
    "def ripser_metric(embeddings, u=None, s=None):\n",
    "    \n",
    "    diagrams = rpp.run(\"--format point-cloud\", embeddings)\n",
    "    persistence = {}\n",
    "\n",
    "    for k in range(len(diagrams)):\n",
    "        persistence_sum = sum([death - birth for birth, death in diagrams[k] if death > birth])\n",
    "        persistence[f\"ripser_sum_H{k}\"] = persistence_sum\n",
    "\n",
    "    return persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e00a1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "os.makedirs('logs/age', exist_ok=True)\n",
    "\n",
    "logger = logging.getLogger(\"my_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "file_handler = logging.FileHandler(\"logs/age/hidden_size_experiment.log\")\n",
    "formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# Удалим другие обработчики\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "logger.info(\"🔧 Логгер настроен вручную\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ae2a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# random_embedding = np.random.rand(100, 8)\n",
    "\n",
    "# # 🔹 Санити-чек\n",
    "# score, elapsed = ripser_metric(random_embedding)\n",
    "# print(f\"Ripser metric: {score:.4f}, computed in {elapsed:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b832a19-eb6d-4968-b7e7-84856ff80d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(train_dict, valid_dict, params, source_features):\n",
    "    splitter = SampleSlices(\n",
    "        split_count=params[\"split_count\"],\n",
    "        cnt_min=params[\"cnt_min\"],\n",
    "        cnt_max=params[\"cnt_max\"],\n",
    "    )\n",
    "\n",
    "    train_data = MultiModalIterableDataset(\n",
    "        data=train_dict,\n",
    "        splitter=splitter,\n",
    "        source_features=source_features,\n",
    "        col_id=\"client_id\",\n",
    "        col_time=\"trans_date\",\n",
    "        source_names=(\"sourceA\", \"sourceB\"),\n",
    "    )\n",
    "\n",
    "    valid_data = MultiModalIterableDataset(\n",
    "        data=valid_dict,\n",
    "        splitter=splitter,\n",
    "        source_features=source_features,\n",
    "        col_id=\"client_id\",\n",
    "        col_time=\"trans_date\",\n",
    "        source_names=(\"sourceA\", \"sourceB\"),\n",
    "    )\n",
    "\n",
    "    data_loader = PtlsDataModule(\n",
    "        train_data=train_data,\n",
    "        train_batch_size=params[\"batch_size\"],\n",
    "        train_num_workers=0,\n",
    "        valid_data=valid_data,\n",
    "    )\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c308cd5-1e80-4cf8-ba00-4858ea2aed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, pl_trainer, inf_test_loader, selected_metrics=None, n_samples=10, sample_fraction=1/20):\n",
    "    import gc\n",
    "    from sklearn.utils import resample\n",
    "    from time import time\n",
    "    logger.info(f\"{sample_fraction=}\")\n",
    "\n",
    "    model.eval()\n",
    "    inference_module = InferenceModuleMultimodal(\n",
    "        model=model,\n",
    "        pandas_output=True,\n",
    "        drop_seq_features=True,\n",
    "        model_out_name=\"emb\",\n",
    "        col_id=\"client_id\",\n",
    "    )\n",
    "    inference_module.model.is_reduce_sequence = True\n",
    "\n",
    "    # Получение эмбеддингов\n",
    "    inf_test_embeddings = pd.concat(\n",
    "        pl_trainer.predict(inference_module, inf_test_loader),\n",
    "        axis=0,\n",
    "    )\n",
    "    embeddings_np = inf_test_embeddings.drop(columns=[\"client_id\"]).to_numpy(dtype=np.float32)\n",
    "    sample_size = max(1, int(sample_fraction * embeddings_np.shape[0]))\n",
    "\n",
    "    # Метрики\n",
    "    available_metrics = {\n",
    "        \"rankme\": rankme,\n",
    "        \"coherence\": coherence,\n",
    "        \"pseudo_condition_number\": pseudo_condition_number,\n",
    "        \"alpha_req\": alpha_req,\n",
    "        \"stable_rank\": stable_rank,\n",
    "        \"ne_sum\": ne_sum,\n",
    "        \"self_clustering\": self_clustering,\n",
    "        \"ripser\": ripser_metric\n",
    "    }\n",
    "    if selected_metrics is None:\n",
    "        selected_metrics = list(available_metrics.keys())\n",
    "\n",
    "    metrics = {name: [] for name in selected_metrics}\n",
    "    times = {name: [] for name in selected_metrics}\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        sample = resample(embeddings_np, n_samples=sample_size, replace=False, random_state=42 + i)\n",
    "        u, s, _ = np.linalg.svd(sample, compute_uv=True, full_matrices=False)\n",
    "\n",
    "        for metric_name in selected_metrics:\n",
    "            if metric_name not in available_metrics:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                t0 = time()\n",
    "                result = available_metrics[metric_name](sample, u=u, s=s)\n",
    "                t = time() - t0\n",
    "\n",
    "                if isinstance(result, dict):\n",
    "                    for subname, val in result.items():\n",
    "                        if subname not in metrics:\n",
    "                            metrics[subname] = []\n",
    "                            times[subname] = []\n",
    "                        metrics[subname].append(val)\n",
    "                        times[subname].append(t)\n",
    "                else:\n",
    "                    if metric_name not in metrics:\n",
    "                        metrics[metric_name] = []\n",
    "                        times[metric_name] = []\n",
    "                    metrics[metric_name].append(result)\n",
    "                    times[metric_name].append(t)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Failed to compute {metric_name} on sample {i}: {e}\")\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    averaged_metrics = {k: np.mean(v) for k, v in metrics.items()}\n",
    "    std_metrics = {k: np.std(v) for k, v in metrics.items()}\n",
    "    \n",
    "    averaged_times = {k: np.mean(v) for k, v in times.items()}\n",
    "    std_times = {k: np.std(v) for k, v in times.items()}\n",
    "\n",
    "    print(\"\\n📊 Средние значения метрик и время вычисления:\")\n",
    "    for metric_name in averaged_metrics:\n",
    "        metric_value = averaged_metrics[metric_name]\n",
    "        metric_time = averaged_times.get(metric_name, None)\n",
    "        print(f\"🧠 {metric_name:30s} = {metric_value:.4f} | ⏱ {metric_time:.4f} сек\")\n",
    "\n",
    "    return averaged_metrics, averaged_times, std_metrics, std_times, inf_test_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5afba88-ca89-4002-9e51-73f0c90458ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "\n",
    "\n",
    "def evaluate_model(model, pl_trainer, checkpoint=None, selected_metrics=None, sample_fraction=1/20):\n",
    "    model.eval()\n",
    "    metrics, times, std_metrics, std_times, inf_test_embeddings = compute_metrics(model, pl_trainer, inf_test_loader, selected_metrics, sample_fraction=sample_fraction)\n",
    "    targets_df = df_target.set_index(\"client_id\")\n",
    "    inf_test_df = inf_test_embeddings.merge(targets_df, how=\"inner\", on=\"client_id\").set_index(\"client_id\")\n",
    "    \n",
    "    X = inf_test_df.drop(columns=[\"bins\"])\n",
    "    y = inf_test_df[\"bins\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    classifier = catboost.CatBoostClassifier(\n",
    "        iterations=150,\n",
    "        random_seed=42,\n",
    "        verbose=0,\n",
    "    )\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy = classifier.score(X_test, y_test)\n",
    "\n",
    "    del classifier\n",
    "    \n",
    "    return metrics, times, std_metrics, std_times, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9423ffb-c641-49da-922a-f99f310a5420",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_params = {\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"split_count\": 3,\n",
    "    \"cnt_min\": 10,\n",
    "    \"cnt_max\": 50,\n",
    "    \"embedding_dim\": 16,  # Размерность эмбеддингов\n",
    "    \"category_embedding_dim\": 8,  # Размерность категорий эмбеддингов\n",
    "    \"hidden_size\": 128,  # Размер скрытого слоя по умолчанию\n",
    "}\n",
    "\n",
    "# Список гиперпараметров для перебора\n",
    "variable_params = {\n",
    "    # \"batch_size\": [32, 64, 128], \n",
    "    # \"learning_rate\": [0.0001, 0.001, 0.05],\n",
    "    # \"split_count\": [2, 3, 5],\n",
    "    # \"cnt_min\": [5, 10, 20],\n",
    "    # \"cnt_max\": [50, 80, 100],\n",
    "    # \"embedding_dim\": [8, 16, 32],\n",
    "    # \"category_embedding_dim\": [8, 16, 24],\n",
    "    \"hidden_size\": [64, 128, 256, 1024],\n",
    "}\n",
    "\n",
    "# Создание списка всех гиперпараметров, которые нужно перебрать\n",
    "all_hyperparameter_grids = []\n",
    "for variable_param_name, variable_param_values in variable_params.items():\n",
    "    for value in variable_param_values:\n",
    "        hyperparameter_grid = {**fixed_params, variable_param_name: value}\n",
    "        all_hyperparameter_grids.append((variable_param_name, hyperparameter_grid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32ff8195-6bc8-45f6-af73-0b9a4dd5a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = [\n",
    "    \"rankme\", \"coherence\", \"pseudo_condition_number\",\n",
    "    \"alpha_req\", \"stable_rank\", \"ne_sum\", \"self_clustering\", \"ripser\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ca1115d-c16e-4c72-a7c6-31d5f9f098dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_embedding_dims = {\n",
    "    \"small_group\": (150, fixed_params[\"category_embedding_dim\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad25eb4a-0a4e-4cd6-9d6b-3e38d3cc3faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "150285f7-e90d-4a43-bc9c-ebe88839196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = \"age/checkpoints\"\n",
    "os.makedirs(checkpoints_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7abe764b-1033-4e80-ac36-a01ea8af5eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SampleSlices(split_count=5, cnt_min=25, cnt_max=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40fce490-8628-4ddb-a0de-88a504127673",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogger(pl.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.early_stopping_epoch = None  # Запомним, на какой эпохе произошла остановка\n",
    "    \n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        train_loss = trainer.callback_metrics.get(\"train_loss\", None)\n",
    "        val_loss = trainer.callback_metrics.get(\"val_loss\", None)\n",
    "        \n",
    "        if train_loss is not None and val_loss is not None:\n",
    "            print(f\"Epoch {trainer.current_epoch}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Если валидационный лосс увеличивается - фиксируем эпоху остановки\n",
    "        if trainer.early_stopping_callback is not None and trainer.early_stopping_callback.wait_count == 0:\n",
    "            self.early_stopping_epoch = trainer.current_epoch\n",
    "\n",
    "\n",
    "custom_logger = CustomLogger()\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    mode=\"min\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1540f7bd-56fe-402f-81e9-f7761c272a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45b5a2f0-27bb-4f76-8eef-e9db0dc3b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm age_tr_params_tun_full.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f3a299f-0870-4455-b906-3c943c2fd927",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "output_csv = \"age_tr_hidden_size2.csv\"\n",
    "\n",
    "\n",
    "metric_keys = [\n",
    "    \"rankme\", \"coherence\", \"pseudo_condition_number\", \n",
    "    \"alpha_req\", \"stable_rank\", \"ne_sum\", \"self_clustering\", \"ripser_sum_H0\", \"ripser_sum_H1\"\n",
    "]\n",
    "\n",
    "columns = (\n",
    "    list(fixed_params.keys()) +\n",
    "    [\"checkpoint\", \"epoch_num\", \"accuracy\", \"early_stop_epoch\", \"hidden_size\", \"sample_fraction\"] +\n",
    "    [f\"metric_{k}\" for k in metric_keys] +\n",
    "    [f\"std_metric_{k}\" for k in metric_keys] +\n",
    "    [f\"time_{k}\" for k in metric_keys] +\n",
    "    [f\"std_time_{k}\" for k in metric_keys]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74305632-67ed-4eb6-aeeb-bb8f4fa57a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dpetrovitch/venv/lib/python3.12/site-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/dpetrovitch/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/dpetrovitch/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/dpetrovitch/experiments/age/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name               | Type                                  | Params | Mode \n",
      "-------------------------------------------------------------------------------------\n",
      "0 | _loss              | ContrastiveLoss                       | 0      | train\n",
      "1 | _seq_encoder       | MultiModalSortTimeSeqEncoderContainer | 33.7 K | train\n",
      "2 | _validation_metric | BatchRecallTopK                       | 0      | train\n",
      "3 | _head              | Head                                  | 0      | train\n",
      "-------------------------------------------------------------------------------------\n",
      "33.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.7 K    Total params\n",
      "0.135     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcb3cb68e9646baad4175e4158ebbbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                       | 0/?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dpetrovitch/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/dpetrovitch/venv/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
      "/home/dpetrovitch/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a608c6b4618413ead83aac84d713217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                              | 0/?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eabb4ab811f4b42aaaf947dfb288729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric loss improved. New best score: 6.007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d9bcce67ba473ea19bd5f347c9c554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric loss improved by 0.741 >= min_delta = 0.0. New best score: 5.267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40b0b3e57c044458952658111ef0a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02646a1d4a22405481457a37854986e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80750ca59e7149ff8246e4106f2153c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric loss improved by 0.019 >= min_delta = 0.0. New best score: 5.248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b91c5546f074d9f82e5d738d4b99b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea659e1576640d6b420d033fded4ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029cb18c219442aeb2da9838a4059154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric loss improved by 0.503 >= min_delta = 0.0. New best score: 4.744\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334e815dcb5345519f3cd7b2fec8f9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4aa6a7f224d4e6ebada0eef38984416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532f6b2029de4d89bb2d44ee9cc48be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5399e8e50f394446ae97afe0a4c55c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                            | 0/?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import time\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from functools import partial\n",
    "\n",
    "cur_time = time()\n",
    "\n",
    "for param in all_hyperparameter_grids:\n",
    "    \n",
    "    logger.info(f'All params are frozen except {param[0]}')\n",
    "    params = param[1]\n",
    "    logger.info(f\"Testing parameters: {params}\")\n",
    "\n",
    "    train_loader = create_datasets(train_dict, valid_dict, params, source_features)\n",
    "\n",
    "    sourceA_encoder_params = dict(\n",
    "        embeddings_noise=0.003,\n",
    "        linear_projection_size=64,\n",
    "        embeddings={\n",
    "            \"small_group\": {\"in\": len(np.unique(sourceA['small_group'])), \"out\": 32}\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    sourceB_encoder_params = dict(\n",
    "        embeddings_noise=0.003,\n",
    "        linear_projection_size=64,\n",
    "        numeric_values={\"amount_rur\": \"identity\"},\n",
    "    )\n",
    "    \n",
    "    sourceA_encoder = TrxEncoder(**sourceA_encoder_params)\n",
    "    sourceB_encoder = TrxEncoder(**sourceB_encoder_params)\n",
    "    \n",
    "    seq_encoder = MultiModalSortTimeSeqEncoderContainer(\n",
    "        trx_encoders={\n",
    "            \"sourceA\": sourceA_encoder,\n",
    "            \"sourceB\": sourceB_encoder,\n",
    "        },\n",
    "        input_size=64,\n",
    "        hidden_size=params[\"hidden_size\"],  # Используем только текущее значение hidden_size\n",
    "        seq_encoder_cls=RnnEncoder,\n",
    "        type=\"gru\",\n",
    "    )\n",
    "\n",
    "    model = CoLESModule(\n",
    "        seq_encoder=seq_encoder,\n",
    "        optimizer_partial=partial(torch.optim.Adam, lr=params[\"learning_rate\"]),\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=10, gamma=0.5),\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor=\"loss\",\n",
    "        patience=5,\n",
    "        mode=\"min\",\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=checkpoints_path,\n",
    "        filename=f\"model_{params['batch_size']}_{params['learning_rate']}_{params['split_count']}_{params['cnt_min']}_{params['cnt_max']}_{params['hidden_size']}{{epoch:02d}}\",\n",
    "        save_top_k=-1,\n",
    "        every_n_epochs=1,\n",
    "    )\n",
    "\n",
    "    # Обучение модели\n",
    "    pl_trainer = pl.Trainer(\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback, custom_logger],\n",
    "        default_root_dir=checkpoints_path,\n",
    "        check_val_every_n_epoch=1,\n",
    "        max_epochs= num_epochs,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        precision=16\n",
    "    )\n",
    "    model.train()\n",
    "    pl_trainer.fit(model, train_loader)\n",
    "\n",
    "    early_stop_epoch = getattr(custom_logger, \"early_stopping_epoch\", None) or num_epochs\n",
    "\n",
    "    # Обработка чекпоинтов\n",
    "    checkpoint_files = glob.glob(f\"{checkpoints_path}/model_{params['batch_size']}_{params['learning_rate']}_{params['split_count']}_{params['cnt_min']}_{params['cnt_max']}_{params['hidden_size']}*.ckpt\")\n",
    "    checkpoint_files.sort()\n",
    "    logger.info(f\"Elapsed time: {time() - cur_time:.2f} seconds\")\n",
    "\n",
    "    logger.info(f'Early stop is {early_stop_epoch}')\n",
    "\n",
    "    for i, checkpoint in enumerate(checkpoint_files):\n",
    "        logger.info(f\"Processing checkpoint number {i}\")\n",
    "        model = CoLESModule.load_from_checkpoint(checkpoint, seq_encoder=seq_encoder)\n",
    "    \n",
    "        # Вычисление метрик, времени, дисперсий и accuracy\n",
    "        metrics, times, std_metrics, std_times, accuracy = evaluate_model(model, pl_trainer, checkpoint, sample_fraction=sample_fraction)\n",
    "    \n",
    "        # Преобразование результатов в плоские словари\n",
    "        metrics_flattened = {f\"metric_{k}\": round(v, 4) for k, v in metrics.items()}\n",
    "        std_metrics_flattened = {f\"std_metric_{k}\": round(v, 4) for k, v in std_metrics.items()}\n",
    "        times_flattened = {f\"time_{k}\": round(v, 4) for k, v in times.items()}\n",
    "        std_times_flattened = {f\"std_time_{k}\": round(v, 4) for k, v in std_times.items()}\n",
    "    \n",
    "        # Сбор всех результатов\n",
    "        new_result = {\n",
    "            **params,\n",
    "            \"checkpoint\": checkpoint,\n",
    "            \"epoch_num\": int(i),\n",
    "            \"accuracy\": accuracy,\n",
    "            \"early_stop_epoch\": int(early_stop_epoch),\n",
    "            \"sample_fraction\": sample_fraction,\n",
    "            **metrics_flattened,\n",
    "            **std_metrics_flattened,\n",
    "            **times_flattened,\n",
    "            **std_times_flattened,\n",
    "        }\n",
    "    \n",
    "        # Сохранение в CSV\n",
    "        results = pd.DataFrame([new_result], columns=columns)\n",
    "\n",
    "        if not os.path.exists(output_csv):  \n",
    "            pd.DataFrame(columns=columns).to_csv(output_csv, mode=\"w\", index=False, header=True)\n",
    "            logger.info('csv file was created!')\n",
    "        \n",
    "        results.to_csv(output_csv, mode=\"a\", header=False, index=False)\n",
    "        \n",
    "\n",
    "        del metrics, accuracy, new_result\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    logger.info(f\"Removing checkpoints for parameters: {params}\")\n",
    "    for checkpoint in checkpoint_files:\n",
    "        os.remove(checkpoint)\n",
    "\n",
    "    del model\n",
    "    del train_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "logger.info(\"Optimization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2679bf0-29dc-41d4-808a-6ec4dfcb1cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
